usage: fairseq-train [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                     [--log-format {json,none,simple,tqdm}]
                     [--tensorboard-logdir TENSORBOARD_LOGDIR]
                     [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu]
                     [--tpu] [--bf16] [--memory-efficient-bf16] [--fp16]
                     [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                     [--fp16-init-scale FP16_INIT_SCALE]
                     [--fp16-scale-window FP16_SCALE_WINDOW]
                     [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                     [--min-loss-scale MIN_LOSS_SCALE]
                     [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                     [--user-dir USER_DIR]
                     [--empty-cache-freq EMPTY_CACHE_FREQ]
                     [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                     [--model-parallel-size MODEL_PARALLEL_SIZE]
                     [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                     [--profile] [--reset-logging]
                     [--criterion {composite_loss,label_smoothed_cross_entropy,sentence_ranking,wav2vec,sentence_prediction,masked_lm,nat_loss,cross_entropy,ctc,label_smoothed_cross_entropy_with_alignment,legacy_masked_lm_loss,adaptive_loss,vocab_parallel_cross_entropy}]
                     [--tokenizer {space,moses,nltk}]
                     [--bpe {byte_bpe,subword_nmt,sentencepiece,bytes,fastbpe,bert,characters,hf_byte_bpe,gpt2}]
                     [--optimizer {sgd,adam,lamb,adafactor,nag,adagrad,adadelta,adamax}]
                     [--lr-scheduler {fixed,tri_stage,manual,reduce_lr_on_plateau,triangular,inverse_sqrt,polynomial_decay,cosine}]
                     [--scoring {chrf,sacrebleu,bleu,wer}] [--task TASK]
                     [--num-workers NUM_WORKERS]
                     [--skip-invalid-size-inputs-valid-test]
                     [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                     [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                     [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                     [--dataset-impl {raw,lazy,cached,mmap,fasta}]
                     [--data-buffer-size DATA_BUFFER_SIZE]
                     [--train-subset TRAIN_SUBSET]
                     [--valid-subset VALID_SUBSET]
                     [--validate-interval VALIDATE_INTERVAL]
                     [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                     [--validate-after-updates VALIDATE_AFTER_UPDATES]
                     [--fixed-validation-seed FIXED_VALIDATION_SEED]
                     [--disable-validation]
                     [--max-tokens-valid MAX_TOKENS_VALID]
                     [--batch-size-valid BATCH_SIZE_VALID]
                     [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                     [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                     [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                     [--distributed-rank DISTRIBUTED_RANK]
                     [--distributed-backend DISTRIBUTED_BACKEND]
                     [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                     [--distributed-port DISTRIBUTED_PORT]
                     [--device-id DEVICE_ID] [--distributed-no-spawn]
                     [--ddp-backend {c10d,no_c10d}]
                     [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                     [--find-unused-parameters] [--fast-stat-sync]
                     [--broadcast-buffers]
                     [--distributed-wrapper {DDP,SlowMo}]
                     [--slowmo-momentum SLOWMO_MOMENTUM]
                     [--slowmo-algorithm SLOWMO_ALGORITHM]
                     [--localsgd-frequency LOCALSGD_FREQUENCY]
                     [--nprocs-per-node NPROCS_PER_NODE]
                     [--pipeline-model-parallel]
                     [--pipeline-balance PIPELINE_BALANCE]
                     [--pipeline-devices PIPELINE_DEVICES]
                     [--pipeline-chunks PIPELINE_CHUNKS]
                     [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                     [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                     [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                     [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                     [--pipeline-checkpoint {always,never,except_last}]
                     [--zero-sharding {none,os}] [--arch ARCH]
                     [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                     [--stop-time-hours STOP_TIME_HOURS]
                     [--clip-norm CLIP_NORM] [--sentence-avg]
                     [--update-freq UPDATE_FREQ] [--lr LR] [--min-lr MIN_LR]
                     [--use-bmuf] [--save-dir SAVE_DIR]
                     [--restore-file RESTORE_FILE]
                     [--finetune-from-model FINETUNE_FROM_MODEL]
                     [--reset-dataloader] [--reset-lr-scheduler]
                     [--reset-meters] [--reset-optimizer]
                     [--optimizer-overrides OPTIMIZER_OVERRIDES]
                     [--save-interval SAVE_INTERVAL]
                     [--save-interval-updates SAVE_INTERVAL_UPDATES]
                     [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                     [--keep-last-epochs KEEP_LAST_EPOCHS]
                     [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS]
                     [--no-save] [--no-epoch-checkpoints]
                     [--no-last-checkpoints] [--no-save-optimizer-state]
                     [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                     [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                     [--checkpoint-suffix CHECKPOINT_SUFFIX]
                     [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                     [--activation-fn {relu,gelu,gelu_fast,gelu_accurate,tanh,linear}]
                     [--dropout D] [--attention-dropout D]
                     [--activation-dropout D] [--encoder-embed-path STR]
                     [--encoder-embed-dim N] [--encoder-ffn-embed-dim N]
                     [--encoder-layers N] [--encoder-attention-heads N]
                     [--encoder-normalize-before] [--encoder-learned-pos]
                     [--decoder-embed-path STR] [--decoder-embed-dim N]
                     [--decoder-ffn-embed-dim N] [--decoder-layers N]
                     [--decoder-attention-heads N] [--decoder-learned-pos]
                     [--decoder-normalize-before] [--decoder-output-dim N]
                     [--share-decoder-input-output-embed]
                     [--share-all-embeddings]
                     [--no-token-positional-embeddings]
                     [--adaptive-softmax-cutoff EXPR]
                     [--adaptive-softmax-dropout D] [--layernorm-embedding]
                     [--no-scale-embedding] [--checkpoint-activations]
                     [--no-cross-attention] [--cross-self-attention]
                     [--encoder-layerdrop D] [--decoder-layerdrop D]
                     [--encoder-layers-to-keep ENCODER_LAYERS_TO_KEEP]
                     [--decoder-layers-to-keep DECODER_LAYERS_TO_KEEP]
                     [--quant-noise-pq D] [--quant-noise-pq-block-size D]
                     [--quant-noise-scalar D] [--pooler-dropout D]
                     [--pooler-activation-fn {relu,gelu,gelu_fast,gelu_accurate,tanh,linear}]
                     [--spectral-norm-classification-head]
                     [--num-classes NUM_CLASSES] [--init-token INIT_TOKEN]
                     [--separator-token SEPARATOR_TOKEN] [--regression-target]
                     [--no-shuffle]
                     [--shorten-method {none,truncate,random_crop}]
                     [--shorten-data-split-list SHORTEN_DATA_SPLIT_LIST]
                     [--add-prev-output-tokens] --langs LANG [--prepend-bos]
                     --src-language SRC_LANGUAGE --tgt-language TGT_LANGUAGE
                     [--classification-head-name CLASSIFICATION_HEAD_NAME]
                     [--adam-betas ADAM_BETAS] [--adam-eps ADAM_EPS]
                     [--weight-decay WEIGHT_DECAY] [--use-old-adam]
                     [--warmup-updates WARMUP_UPDATES]
                     [--force-anneal FORCE_ANNEAL]
                     [--end-learning-rate END_LEARNING_RATE] [--power POWER]
                     [--total-num-update TOTAL_NUM_UPDATE] [--pad PAD]
                     [--eos EOS] [--unk UNK]
                     FILE
fairseq-train: error: argument --dropout: invalid float value: '{0.5:-0.1}'
